{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb2fc3e-97fd-4c3f-964c-f30c6bcad27d",
   "metadata": {},
   "source": [
    "\n",
    "## Notebook 08: Validación Cruzada (K-Fold)\n",
    "\n",
    " **Objetivo**: Implementar K-Fold Cross-Validation con Regresión Logística para  asegurar que nuestro modelo del Top 25% de contratos sea estadísticamente robusto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a53306f-69ed-43dc-9e86-f4a41b87b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# %%\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SECOP_CrossValidation_Logistica\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3feabc-277a-4db3-bc78-e4509d469fcc",
   "metadata": {},
   "source": [
    "### PASO 0: Preparación de Datos (Binarización al Percentil 75)\n",
    "Replicamos la lógica del Notebook 07 para tener etiquetas 0 y 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50e4800-4ebd-44df-adfb-014d7f162f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_raw = spark.read.parquet(\"/opt/spark-data/processed/secop_ml_ready.parquet\")\n",
    "\n",
    "# Crear etiquetas binarias (Top 25%)\n",
    "discretizer = QuantileDiscretizer(numBuckets=4, inputCol=\"label\", outputCol=\"cuartil\")\n",
    "df_cuartiles = discretizer.fit(df_raw).transform(df_raw)\n",
    "\n",
    "df_final = df_cuartiles.withColumn(\"label_bin\", when(col(\"cuartil\") == 3.0, 1.0).otherwise(0.0)) \\\n",
    "                       .select(\"features\", col(\"label_bin\").alias(\"label\"))\n",
    "\n",
    "train, test = df_final.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9cdc6-cf52-4de9-ae48-5fd85a43230c",
   "metadata": {},
   "source": [
    "\n",
    "### RETO 1: Entender K-Fold Cross-Validation\n",
    " **Preguntas conceptuales (K=5)**:\n",
    "1. **Subconjuntos**: Los datos de train se dividen en 5 subconjuntos (folds).\n",
    " 2. **Modelos entrenados**: Se entrenan 5 modelos por cada combinación de parámetros.\n",
    " 3. **Porcentaje validación**: En cada iteración se usa el 20% para validar y 80% para entrenar.\n",
    "4. **Métrica final**: El promedio de las métricas (AUC) de los 5 experimentos.\n",
    "\n",
    "**Ventaja**: Evita que los resultados dependan de una división \"con suerte\" de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef0759-d2f1-48d3-ae22-cf7db9fda55d",
   "metadata": {},
   "source": [
    "## RETO 2: Crear el Modelo Base y Evaluador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62434f8c-a995-4abe-9dc3-48b752ecfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base sin parámetros fijos (los buscaremos en el Grid)\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=50)\n",
    "\n",
    "# Evaluador para clasificación binaria\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    metricName=\"areaUnderROC\" # AUC es la métrica estándar\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3c955-0c43-4d53-9724-0d31a115dde5",
   "metadata": {},
   "source": [
    "\n",
    "## RETO 3: Construir el ParamGrid\n",
    "\n",
    "**Pregunta**: Si probamos 2 valores de regParam y 2 de elasticNetParam con K=3, \n",
    "entrenaremos (2x2) * 3 = 12 modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f405366e-7eaf-4d3c-9678-d435642c77ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaciones en el grid: 4\n"
     ]
    }
   ],
   "source": [
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "print(f\"Combinaciones en el grid: {len(param_grid)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa9d49-f00b-4934-8e6b-2d7d1407c444",
   "metadata": {},
   "source": [
    "\n",
    "## RETO 4: Configurar CrossValidator\n",
    "\n",
    "**Elección de K**: Usaremos **K=3** para este ejercicio debido al volumen de datos  del SECOP, buscando eficiencia sin perder robustez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1038286e-1ceb-4485-8306-e1779d2e0b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurado: Cross-Validation con K=3 folds\n"
     ]
    }
   ],
   "source": [
    "crossval = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Configurado: Cross-Validation con K=3 folds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75b02c-edf5-439d-9e77-b16f3d5fd001",
   "metadata": {},
   "source": [
    "## RETO 5: Ejecutar Cross-Validation y Analizar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3ae9322-adfd-4099-97bd-7e977e45904d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con Cross-Validation (esto puede tardar unos minutos)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MÉTRICAS PROMEDIO (AUC) POR CONFIGURACIÓN ===\n",
      "Config 1: λ=0.01, α=0.0 -> AUC=0.8270 <-- MEJOR\n",
      "Config 2: λ=0.01, α=1.0 -> AUC=0.8218\n",
      "Config 3: λ=0.10, α=0.0 -> AUC=0.8263\n",
      "Config 4: λ=0.10, α=1.0 -> AUC=0.7893\n",
      "\n",
      "=== RENDIMIENTO FINAL DEL MEJOR MODELO ===\n",
      "AUC promedio en CV: 0.8270\n",
      "AUC final en Test:  0.8262\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando con Cross-Validation (esto puede tardar unos minutos)...\")\n",
    "cv_model = crossval.fit(train)\n",
    "\n",
    "# Analizar métricas promedio\n",
    "avg_metrics = cv_model.avgMetrics\n",
    "best_metric_idx = avg_metrics.index(max(avg_metrics)) # En AUC buscamos el MÁXIMO\n",
    "\n",
    "print(\"\\n=== MÉTRICAS PROMEDIO (AUC) POR CONFIGURACIÓN ===\")\n",
    "for i, metric in enumerate(avg_metrics):\n",
    "    params = param_grid[i]\n",
    "    reg = params.get(lr.regParam)\n",
    "    elastic = params.get(lr.elasticNetParam)\n",
    "    marker = \" <-- MEJOR\" if i == best_metric_idx else \"\"\n",
    "    print(f\"Config {i+1}: λ={reg:.2f}, α={elastic:.1f} -> AUC={metric:.4f}{marker}\")\n",
    "\n",
    "# %%\n",
    "# Evaluar el mejor modelo en el set de Test (datos nunca vistos)\n",
    "best_model = cv_model.bestModel\n",
    "predictions = best_model.transform(test)\n",
    "auc_test = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"\\n=== RENDIMIENTO FINAL DEL MEJOR MODELO ===\")\n",
    "print(f\"AUC promedio en CV: {max(avg_metrics):.4f}\")\n",
    "print(f\"AUC final en Test:  {auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19082e6-cdd6-4acc-9691-d65e2042dc8e",
   "metadata": {},
   "source": [
    "## RETO 6: Comparar CV vs Simple Split\n",
    "\n",
    "**Confiabilidad**: La métrica de CV es más confiable porque representa el comportamiento \n",
    " del modelo en diferentes \"escenarios\" de los datos, reduciendo el sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeafaf30-862a-4e9f-a2eb-d4172abf82e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC con CV:      0.8262\n",
      "AUC sin CV:      0.8263\n",
      "Diferencia:      0.000042\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento simple con los mismos parámetros\n",
    "lr_simple = LogisticRegression(\n",
    "    featuresCol=\"features\", labelCol=\"label\",\n",
    "    regParam=best_model.getRegParam(),\n",
    "    elasticNetParam=best_model.getElasticNetParam()\n",
    ")\n",
    "model_simple = lr_simple.fit(train)\n",
    "auc_simple = evaluator.evaluate(model_simple.transform(test))\n",
    "\n",
    "print(f\"AUC con CV:      {auc_test:.4f}\")\n",
    "print(f\"AUC sin CV:      {auc_simple:.4f}\")\n",
    "print(f\"Diferencia:      {abs(auc_test - auc_simple):.6f}\")\n",
    "\n",
    "# ## Preguntas de Reflexión\n",
    "#\n",
    "# 1. **¿K=3 vs K=10?**: K=3 para datasets grandes (ahorro de tiempo); K=10 para datasets pequeños (máxima robustez).\n",
    "# 2. **¿CV reemplaza el Test Set?**: NO. El test set es la única prueba \"ciega\" final. CV se usa para elegir el mejor modelo dentro del entrenamiento.\n",
    "# 3. **¿Dataset de 100 registros?**: Usaría K=10 o incluso Leave-One-Out CV para aprovechar cada dato.\n",
    "# 4. **¿Time Series?**: No se puede usar K-Fold aleatorio. Se debe usar \"TimeSeriesSplit\" donde el entrenamiento siempre es anterior a la validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce4d517f-a19d-40a3-a0f4-f6173075697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo optimizado guardado en /opt/spark-data/processed/modelo_final_cv\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo final optimizado\n",
    "best_model.write().overwrite().save(\"/opt/spark-data/processed/modelo_final_cv\")\n",
    "print(\"Modelo optimizado guardado en /opt/spark-data/processed/modelo_final_cv\")\n",
    "\n",
    "# %%\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe498641-4ecc-40d4-9e5e-9b13aebf30e8",
   "metadata": {},
   "source": [
    "La diferencia entre el AUC obtenido con Validación Cruzada y el entrenamiento simple es de apenas 0.000042, el modelo siempre identifica los contratos de alto valor con la misma precisión. el mejor modelo fue la Config 1 ($\\lambda=0.01, \\alpha=0.0$). Esto indica que una regularización suave tipo Ridge es preferible a Lasso ($\\alpha=1.0$). Ridge mantiene todas las variables pero reduce su impacto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
