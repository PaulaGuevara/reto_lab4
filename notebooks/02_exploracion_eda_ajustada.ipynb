{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Análisis Exploratorio y Limpieza\\n",
    "**Fusión de EDA + transformación Silver (solo columnas ML)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\\n",
    "from pyspark.sql.functions import (\\n",
    "    col, count, sum as spark_sum, avg, min as spark_min, max as spark_max,\\n",
    "    stddev, isnan, when, isnull, desc, to_date, year, month, percentile_approx,\\n",
    "    datediff, upper, lit\\n",
    ")\\n",
    "from pyspark.sql.types import DecimalType, TimestampType, DateType\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "import pandas as pd\\n",
    "\\n",
    "spark = SparkSession.builder \\\\\\n",
    "    .appName(\"SECOP_EDA_Clean\") \\\\\\n",
    "    .master(\"spark://spark-master:7077\") \\\\\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\\\\n",
    "    .getOrCreate()\\n",
    "\\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde Parquet generado en ingesta\\n",
    "df = spark.read.parquet(\"/opt/spark-data/raw/secop_contratos.parquet\")\\n",
    "print(f\"Registros crudos: {df.count():,}\")\\n",
    "print(f\"Columnas: {len(df.columns)}\")\\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estadísticas descriptivas (Reto 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir target a numérico\\n",
    "df = df.withColumn(\"valor_del_contrato_num\", col(\"valor_del_contrato\").cast(\"double\"))\\n",
    "df.describe([\"valor_del_contrato_num\", \"dias_adicionados\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de valores nulos y estrategia (Reto 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = df.select([\\n",
    "    count(when(isnull(c) | isnan(c), c)).alias(c)\\n",
    "    for c in df.columns\\n",
    "])\\n",
    "null_df = null_counts.toPandas().T\\n",
    "null_df.columns = ['null_count']\\n",
    "null_df['null_percentage'] = (null_df['null_count'] / df.count()) * 100\\n",
    "null_df = null_df.sort_values('null_count', ascending=False)\\n",
    "print(null_df[null_df['null_count'] > 0])\\n",
    "\\n",
    "# Estrategia: eliminar filas con target nulo; para categóricas se imputará más adelante o se usarán como \"Desconocido\"\\n",
    "df = df.filter(col(\"valor_del_contrato_num\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explorar variable objetivo (Reto 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\\n",
    "    spark_min(\"valor_del_contrato_num\").alias(\"Min\"),\\n",
    "    spark_max(\"valor_del_contrato_num\").alias(\"Max\"),\\n",
    "    avg(\"valor_del_contrato_num\").alias(\"Promedio\"),\\n",
    "    stddev(\"valor_del_contrato_num\").alias(\"Desv_Std\"),\\n",
    "    percentile_approx(\"valor_del_contrato_num\", 0.5).alias(\"Mediana\")\\n",
    ").show()\\n",
    "\\n",
    "# Distribución por rangos\\n",
    "df.select(\\n",
    "    count(when(col(\"valor_del_contrato_num\") < 1e7, True)).alias(\"< 10M\"),\\n",
    "    count(when((col(\"valor_del_contrato_num\") >= 1e7) & (col(\"valor_del_contrato_num\") < 1e8), True)).alias(\"10M-100M\"),\\n",
    "    count(when((col(\"valor_del_contrato_num\") >= 1e8) & (col(\"valor_del_contrato_num\") < 1e9), True)).alias(\"100M-1B\"),\\n",
    "    count(when(col(\"valor_del_contrato_num\") >= 1e9, True)).alias(\"> 1B\")\\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribución por departamento (Reto 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept = df.groupBy(\"departamento\") \\\\\\n",
    "    .agg(\\n",
    "        count(\"*\").alias(\"num_contratos\"),\\n",
    "        spark_sum(\"valor_del_contrato_num\").alias(\"valor_total\")\\n",
    "    ) \\\\\\n",
    "    .orderBy(desc(\"num_contratos\"))\\n",
    "df_dept.show(10, truncate=False)\\n",
    "\\n",
    "# Gráfico\\n",
    "pdf_dept = df_dept.limit(10).toPandas()\\n",
    "plt.figure(figsize=(12,5))\\n",
    "plt.subplot(1,2,1)\\n",
    "plt.barh(pdf_dept['departamento'], pdf_dept['num_contratos'])\\n",
    "plt.xlabel('Número de Contratos')\\n",
    "plt.title('Top 10 Departamentos por Contratos')\\n",
    "plt.subplot(1,2,2)\\n",
    "plt.barh(pdf_dept['departamento'], pdf_dept['valor_total']/1e9)\\n",
    "plt.xlabel('Valor Total (Miles de Millones COP)')\\n",
    "plt.title('Top 10 Departamentos por Valor Total')\\n",
    "plt.tight_layout()\\n",
    "plt.savefig('/opt/spark-data/processed/eda_departamentos.png', dpi=150, bbox_inches='tight')\\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tipo de contrato y estado (Reto 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"tipo_de_contrato\").count().orderBy(desc(\"count\")).show(10, truncate=False)\\n",
    "df.groupBy(\"estado_contrato\").count().orderBy(desc(\"count\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detección de outliers con IQR (Reto 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = df.approxQuantile(\"valor_del_contrato_num\", [0.25, 0.5, 0.75], 0.01)\\n",
    "q1, q3 = percentiles[0], percentiles[2]\\n",
    "iqr = q3 - q1\\n",
    "lower_bound = q1 - 1.5 * iqr\\n",
    "upper_bound = q3 + 1.5 * iqr\\n",
    "\\n",
    "num_outliers = df.filter(\\n",
    "    (col(\"valor_del_contrato_num\") < lower_bound) |\\n",
    "    (col(\"valor_del_contrato_num\") > upper_bound)\\n",
    ").count()\\n",
    "\\n",
    "print(f\"Q1: {q1:,.2f}, Q3: {q3:,.2f}, IQR: {iqr:,.2f}\")\\n",
    "print(f\"Rango normal: ${lower_bound:,.2f} - ${upper_bound:,.2f}\")\\n",
    "print(f\"Outliers: {num_outliers:,} ({num_outliers/df.count()*100:.2f}%)\")\\n",
    "\\n",
    "# Estrategia: eliminamos outliers extremos para mejorar el modelo\\n",
    "df_clean = df.filter(\\n",
    "    (col(\"valor_del_contrato_num\") >= lower_bound) &\\n",
    "    (col(\"valor_del_contrato_num\") <= upper_bound)\\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Análisis temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal = df_clean.withColumn(\"fecha_firma_dt\", to_date(\"fecha_de_firma\")) \\\\\\n",
    "                     .withColumn(\"anio\", year(\"fecha_firma_dt\")) \\\\\\n",
    "                     .withColumn(\"mes\", month(\"fecha_firma_dt\"))\\n",
    "df_temporal.groupBy(\"anio\", \"mes\").count().orderBy(\"anio\", \"mes\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza adicional (calidad de datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar valores inválidos en columnas clave\\n",
    "df_clean = df_clean.filter(\\n",
    "    col(\"departamento\").isNotNull() &\\n",
    "    (upper(col(\"departamento\")) != \"NO DEFINIDO\") &\\n",
    "    col(\"tipo_de_contrato\").isNotNull() &\\n",
    "    col(\"estado_contrato\").isNotNull()\\n",
    ")\\n",
    "\\n",
    "# Convertir días adicionados a numérico (rellenar nulos con 0)\\n",
    "df_clean = df_clean.withColumn(\"dias_adicionados_num\", col(\"dias_adicionados\").cast(\"int\"))\\n",
    "df_clean = df_clean.fillna({\"dias_adicionados_num\": 0})\\n",
    "\\n",
    "print(f\"Registros después de limpieza: {df_clean.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar dataset limpio para feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/opt/spark-data/processed/secop_eda.parquet\"\\n",
    "df_clean.write.mode(\"overwrite\").parquet(output_path)\\n",
    "print(f\"Dataset limpio guardado en: {output_path}\")\\n",
    "\\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}