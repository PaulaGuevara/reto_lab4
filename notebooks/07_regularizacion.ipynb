{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a407864-130b-4524-86bf-1d8af3da7b6c",
   "metadata": {},
   "source": [
    "\n",
    "## Notebook 07: Regularización L1, L2 y ElasticNet (Clasificación)\n",
    "### **Objetivo**: Comparar Ridge (L2), Lasso (L1) y ElasticNet usando Regresión Logística para predecir contratos de \"Alto Impacto\" (Top 25% del mercado).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f6353f-c132-4d8e-b05f-7e74e4fd6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.sql.functions import col, when\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# %%\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SECOP_Regularizacion_Logistica\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9c445-a06b-46d1-b146-bc064099c60d",
   "metadata": {},
   "source": [
    "\n",
    " ###  Carga y Binarización (Percentil 75)\n",
    " Transformamos el problema de regresión a clasificación binaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6548cd9a-821a-41f3-b0db-79adb9728722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros entrenamiento: 309,240\n",
      "Registros prueba: 132,708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_raw = spark.read.parquet(\"/opt/spark-data/processed/secop_ml_ready.parquet\")\n",
    "\n",
    "# Usamos 'label' (que tiene el valor numérico) para crear los cuartiles\n",
    "discretizer = QuantileDiscretizer(\n",
    "    numBuckets=4, \n",
    "    inputCol=\"label\", \n",
    "    outputCol=\"cuartil\"\n",
    ")\n",
    "\n",
    "df_cuartiles = discretizer.fit(df_raw).transform(df_raw)\n",
    "\n",
    "# Clase 1: Top 25% (cuartil 3.0). Clase 0: Resto.\n",
    "df_final = df_cuartiles.withColumnRenamed(\"label\", \"valor_original\") \\\n",
    "                       .withColumn(\"label\", when(col(\"cuartil\") == 3.0, 1.0).otherwise(0.0)) \\\n",
    "                       .select(\"features\", \"label\")\n",
    "\n",
    "train, test = df_final.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(f\"Registros entrenamiento: {train.count():,}\")\n",
    "print(f\"Registros prueba: {test.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca02ca-4ac4-48f0-89ed-bdebd6a783f1",
   "metadata": {},
   "source": [
    "\n",
    "## RETO 1: Entender la Regularización\n",
    "\n",
    "**Respuesta**: El escenario de AUC train alto y AUC test bajo indica **Overfitting**. \n",
    "La regularización ayuda penalizando la complejidad del modelo, evitando que se ajuste a ruidos específicos de los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20623a06-eba2-487f-9d8c-1f94b4503175",
   "metadata": {},
   "source": [
    "\n",
    "## RETO 2: Configurar el Evaluador\n",
    "\n",
    "**Objetivo**: Crear un evaluador para clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969f76d1-ba16-4257-b5f7-7c59da422ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos areaUnderROC (AUC) como métrica principal para clasificación binaria\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b30eb5-ff33-4666-8db1-5d81c2ba1f34",
   "metadata": {},
   "source": [
    "\n",
    "## RETO 3: Experimento de Regularización\n",
    "Probaremos combinaciones de λ (regParam) y α (elasticNetParam).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b6f948-115c-4dec-b7e6-cf843773002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaciones totales: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base (Sin Reg)       | λ= 0.00 | α=0.0 | AUC Test: 0.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base (Sin Reg)       | λ= 0.00 | α=0.5 | AUC Test: 0.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base (Sin Reg)       | λ= 0.00 | α=1.0 | AUC Test: 0.8266\n",
      "Ridge (L2)           | λ= 0.01 | α=0.0 | AUC Test: 0.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet           | λ= 0.01 | α=0.5 | AUC Test: 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (L1)           | λ= 0.01 | α=1.0 | AUC Test: 0.8221\n",
      "Ridge (L2)           | λ= 0.10 | α=0.0 | AUC Test: 0.8262\n",
      "ElasticNet           | λ= 0.10 | α=0.5 | AUC Test: 0.7976\n",
      "Lasso (L1)           | λ= 0.10 | α=1.0 | AUC Test: 0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (L2)           | λ= 1.00 | α=0.0 | AUC Test: 0.8219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet           | λ= 1.00 | α=0.5 | AUC Test: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (L1)           | λ= 1.00 | α=1.0 | AUC Test: 0.5000\n"
     ]
    }
   ],
   "source": [
    "reg_params = [0.0, 0.01, 0.1, 1.0]\n",
    "elastic_params = [0.0, 0.5, 1.0] # 0.0=Ridge, 1.0=Lasso\n",
    "\n",
    "print(f\"Combinaciones totales: {len(reg_params) * len(elastic_params)}\")\n",
    "\n",
    "# %%\n",
    "resultados = []\n",
    "\n",
    "for reg in reg_params:\n",
    "    for elastic in elastic_params:\n",
    "        # 1. Configurar Regresión Logística\n",
    "        lr = LogisticRegression(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            maxIter=50,\n",
    "            regParam=reg,\n",
    "            elasticNetParam=elastic\n",
    "        )\n",
    "\n",
    "        # 2. Entrenar\n",
    "        model = lr.fit(train)\n",
    "        \n",
    "        # 3. Evaluar\n",
    "        predictions = model.transform(test)\n",
    "        auc_test = evaluator.evaluate(predictions)\n",
    "        auc_train = model.summary.areaUnderROC\n",
    "\n",
    "        # Determinar tipo de regularización\n",
    "        if reg == 0.0: reg_type = \"Base (Sin Reg)\"\n",
    "        elif elastic == 0.0: reg_type = \"Ridge (L2)\"\n",
    "        elif elastic == 1.0: reg_type = \"Lasso (L1)\"\n",
    "        else: reg_type = \"ElasticNet\"\n",
    "\n",
    "        resultados.append({\n",
    "            \"regParam\": reg,\n",
    "            \"elasticNetParam\": elastic,\n",
    "            \"tipo\": reg_type,\n",
    "            \"auc_test\": auc_test,\n",
    "            \"auc_train\": auc_train\n",
    "        })\n",
    "\n",
    "        print(f\"{reg_type:20s} | λ={reg:5.2f} | α={elastic:.1f} | AUC Test: {auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a91a2b-1c42-41f0-a69f-880ec5b39bee",
   "metadata": {},
   "source": [
    "\n",
    "## RETO 4: Analizar Resultados\n",
    "\n",
    "**Objetivo**: Identificar el modelo con mayor AUC en el set de prueba.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440e3408-23e9-44a2-8bc9-76a4400cff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTADOS ORDENADOS ---\n",
      " regParam  elasticNetParam           tipo  auc_test  auc_train\n",
      "     0.00              0.5 Base (Sin Reg)  0.826729   0.826985\n",
      "     0.00              0.0 Base (Sin Reg)  0.826670   0.826985\n",
      "     0.01              0.0     Ridge (L2)  0.826658   0.827009\n",
      "     0.00              1.0 Base (Sin Reg)  0.826645   0.827015\n",
      "     0.10              0.0     Ridge (L2)  0.826217   0.826276\n",
      "     0.01              0.5     ElasticNet  0.823898   0.823577\n",
      "     0.01              1.0     Lasso (L1)  0.822112   0.821761\n",
      "     1.00              0.0     Ridge (L2)  0.821869   0.822013\n",
      "     0.10              0.5     ElasticNet  0.797608   0.795743\n",
      "     0.10              1.0     Lasso (L1)  0.791319   0.789208\n",
      "     1.00              0.5     ElasticNet  0.500000   0.500000\n",
      "     1.00              1.0     Lasso (L1)  0.500000   0.500000\n",
      "\n",
      "GANADOR: Base (Sin Reg) con AUC=0.8267\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "mejor_modelo_data = df_resultados.loc[df_resultados['auc_test'].idxmax()]\n",
    "\n",
    "print(\"\\n--- RESULTADOS ORDENADOS ---\")\n",
    "print(df_resultados.sort_values(by=\"auc_test\", ascending=False).to_string(index=False))\n",
    "\n",
    "print(f\"\\nGANADOR: {mejor_modelo_data['tipo']} con AUC={mejor_modelo_data['auc_test']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f4ff8-b7f9-4ce3-a0a9-8083acd3ef6a",
   "metadata": {},
   "source": [
    "\n",
    " ## RETO 5: Comparar Overfitting\n",
    "\n",
    "**Objetivo**: Analizar la brecha (Gap) entre Train y Test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1cd6e7-03ea-47ab-b75d-86c0cfa78e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ANÁLISIS DE BRECHA (OVERFITTING) ---\n",
      "              tipo  regParam       gap\n",
      "8       Lasso (L1)      0.10 -0.002111\n",
      "7       ElasticNet      0.10 -0.001865\n",
      "5       Lasso (L1)      0.01 -0.000351\n",
      "4       ElasticNet      0.01 -0.000321\n",
      "10      ElasticNet      1.00  0.000000\n",
      "11      Lasso (L1)      1.00  0.000000\n",
      "6       Ridge (L2)      0.10  0.000059\n",
      "9       Ridge (L2)      1.00  0.000144\n",
      "1   Base (Sin Reg)      0.00  0.000256\n",
      "0   Base (Sin Reg)      0.00  0.000315\n",
      "3       Ridge (L2)      0.01  0.000351\n",
      "2   Base (Sin Reg)      0.00  0.000370\n"
     ]
    }
   ],
   "source": [
    "df_resultados['gap'] = df_resultados['auc_train'] - df_resultados['auc_test']\n",
    "print(\"\\n--- ANÁLISIS DE BRECHA (OVERFITTING) ---\")\n",
    "print(df_resultados[['tipo', 'regParam', 'gap']].sort_values(by='gap'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e1a17-8d94-4d5b-8c27-a5e684807073",
   "metadata": {},
   "source": [
    "## RETO 6: Entrenar y Guardar Modelo Final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc66f21-07d2-49dc-8a49-e2050e737160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Modelo guardado exitosamente.\n",
      "Lasso λ= 0.01 | Variables eliminadas: 49 de 64\n",
      "Lasso λ= 0.10 | Variables eliminadas: 62 de 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso λ= 1.00 | Variables eliminadas: 64 de 64\n"
     ]
    }
   ],
   "source": [
    "lr_final = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    maxIter=100,\n",
    "    regParam=mejor_modelo_data['regParam'],\n",
    "    elasticNetParam=mejor_modelo_data['elasticNetParam']\n",
    ")\n",
    "\n",
    "modelo_final = lr_final.fit(train)\n",
    "modelo_final.write().overwrite().save(\"/opt/spark-data/processed/modelo_logistico_final\")\n",
    "print(f\"\\n✓ Modelo guardado exitosamente.\")\n",
    "\n",
    "## RETO BONUS: Efecto Lasso (Sparsity)\n",
    "\n",
    "for reg in [0.01, 0.1, 1.0]:\n",
    "    m = LogisticRegression(regParam=reg, elasticNetParam=1.0).fit(train)\n",
    "    coefs = m.coefficients.toArray()\n",
    "    zeros = np.sum(np.abs(coefs) < 1e-6)\n",
    "    print(f\"Lasso λ={reg:5.2f} | Variables eliminadas: {zeros} de {len(coefs)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Preguntas de Reflexión\n",
    "# 1. **¿Ridge vs Lasso?**: Ridge si todas las variables son importantes; Lasso para simplificar el modelo.\n",
    "# 2. **¿regParam gigante?**: Genera Underfitting (el modelo es demasiado simple).\n",
    "# 3. **¿Modelo base mejor?**: Solo si el gap con train es casi cero y el rendimiento es alto.\n",
    "\n",
    "# %%\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef05bd2-455d-48b7-a579-4ddcca63f663",
   "metadata": {},
   "source": [
    "la información importante para predecir contratos de alto valor está concentrada en unas pocas variables clave\n",
    "\n",
    "El ganador fue el modelo sin regularización (regParam=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
